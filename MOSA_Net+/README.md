# MOSA-Net+ : An improved version of MOSA-Net 

This section of this repository aims to introduce an improved version of MOSA-Net model, namely MOSA-Net + (Top performance in Track 3 <a href="https://arxiv.org/pdf/2310.02640.pdf" target="_blank">VoiceMOS Challenge 2023</a>), which leverages the acoustic features from <a href="https://github.com/openai/whisper" target="_blank">Whisper</a>. The details of the model architecture can be found in our <a href="https://arxiv.org/pdf/2309.12766.pdf" target="_blank">here.</a> 

### TF Version ###
Please kindly check the following folder for TF implementation <a href="https://github.com/dhimasryan/MOSA-Net-Cross-Domain/tree/main/MOSA_Net%2B/TF_version" target="_blank">MOSA-Net-Cross-Domain/MOSA_Net+/TF_version/</a>

### Citation ###

Please kindly cite our paper, if you find this code is useful.

<a id="1"></a> 
R. E. Zezario, S. -W. Fu, F. Chen, C. -S. Fuh, H. -M. Wang and Y. Tsao, "Deep Learning-Based Non-Intrusive Multi-Objective Speech Assessment Model With Cross-Domain Features," in IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 31, pp. 54-70, 2023, doi: 10.1109/TASLP.2022.3205757.

R. E. Zezario, Y.-W. Chen, S.-W. Fu, Y. Tsao, H.-M. Wang, C.-S. Fuh, "A Study on Incorporating Whisper for Robust Speech Assessment," IEEE ICME 2024, July 2024, (Top Performance on the Track 3 - VoiceMOS Challenge 2023)
